{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils.create_features_utils import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import models, layers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import metrics\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read match data with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/wimbledon_matches_with_feature.csv')\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "df['diff_rank'] = df['player_0_rank'] - df['player_1_rank']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = [\n",
    " 'diff_rank',\n",
    " 'diff_match_win_percent',\n",
    " 'diff_games_win_percent',\n",
    " 'diff_5_set_match_win_percent',\n",
    " 'diff_close_sets_percent',\n",
    " 'diff_match_win_percent_grass',\n",
    " 'diff_games_win_percent_grass',\n",
    " 'diff_5_set_match_win_percent_grass',\n",
    " 'diff_close_sets_percent_grass',\n",
    " 'diff_match_win_percent_52',\n",
    " 'diff_games_win_percent_52',\n",
    " 'diff_5_set_match_win_percent_52',\n",
    " 'diff_close_sets_percent_52',\n",
    " 'diff_match_win_percent_grass_60',\n",
    " 'diff_games_win_percent_grass_60',\n",
    " 'diff_5_set_match_win_percent_grass_60',\n",
    " 'diff_close_sets_percent_grass_60',\n",
    " 'diff_match_win_percent_hh',\n",
    " 'diff_games_win_percent_hh',\n",
    " 'diff_match_win_percent_grass_hh',\n",
    " 'diff_games_win_percent_grass_hh']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data intro Train (80 %) and Test (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df.outcome\n",
    "features = df[features_list]\n",
    "\n",
    "train_features, test_features, train_target, test_target = train_test_split(features, target, test_size=0.20, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the neural network. \n",
    "### Details\n",
    "    - Number of Layers: 3. (2 Hidden Layers)\n",
    "    - Number of Neuros in each layer: 64->32->1\n",
    "    - Activation relu->relu->sigmoid\n",
    "    - Stop if validation loss does not improve for 500 epochs\n",
    "    - Save the best model which gives the maximum validation accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.60132, saving model to data/best_model.h5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.60132\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.60132\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.60132 to 0.57316, saving model to data/best_model.h5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.57316 to 0.56665, saving model to data/best_model.h5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.56665 to 0.55409, saving model to data/best_model.h5\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.55409\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.55409\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.55409 to 0.54758, saving model to data/best_model.h5\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.54758\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.54758 to 0.53290, saving model to data/best_model.h5\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.53290\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.53290 to 0.52931, saving model to data/best_model.h5\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.52931 to 0.52548, saving model to data/best_model.h5\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.52548 to 0.52209, saving model to data/best_model.h5\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.52209\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.52209 to 0.52150, saving model to data/best_model.h5\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.52150\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.52150\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.52150 to 0.51554, saving model to data/best_model.h5\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.51554\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.51554\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.51554\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.51554\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.51554 to 0.51414, saving model to data/best_model.h5\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.51414\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.51414\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.51414\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.51414\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.51414\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.51414\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.51414\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.51414 to 0.50616, saving model to data/best_model.h5\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.50616\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.50616\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.50616\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.50616\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.50616\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.50616\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.50616\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.50616\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.50616 to 0.50450, saving model to data/best_model.h5\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.50450\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.50450\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.50450\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.50450\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.50450 to 0.50266, saving model to data/best_model.h5\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.50266 to 0.50189, saving model to data/best_model.h5\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.50189\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.50189\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.50189\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.50189\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.50189\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.50189 to 0.50062, saving model to data/best_model.h5\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.50062\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.50062\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.50062\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.50062\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.50062\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.50062\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.50062\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.50062\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.50062\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.50062\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.50062\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.50062 to 0.49835, saving model to data/best_model.h5\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.49835 to 0.49794, saving model to data/best_model.h5\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.49794\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.49794\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.49794\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.49794 to 0.49749, saving model to data/best_model.h5\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.49749 to 0.49683, saving model to data/best_model.h5\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.49683\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.49683\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.49683 to 0.49663, saving model to data/best_model.h5\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.49663\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.49663\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.49663 to 0.49654, saving model to data/best_model.h5\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.49654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00149: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.49654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00317: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.49654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00479: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 0.49654\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 0.49654\n"
     ]
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(units=64, activation='relu', input_shape=(len(features.columns),)))\n",
    "network.add(layers.Dense(units=32, activation='relu'))\n",
    "network.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "network.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=500)\n",
    "mc = ModelCheckpoint('data/best_model.h5', monitor='val_loss', mode='min', verbose=2, save_best_only=True)\n",
    "\n",
    "history = network.fit(train_features, train_target, \n",
    "            epochs=1000, verbose=0, batch_size=128, \n",
    "            validation_data=(test_features, test_target), callbacks=[es, mc]) \n",
    "\n",
    "saved_model = load_model('data/best_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.772, Test Accuracy: 0.773\n"
     ]
    }
   ],
   "source": [
    "_, train_acc = saved_model.evaluate(train_features, train_target, verbose=0)\n",
    "_, test_acc = saved_model.evaluate(test_features, test_target, verbose=0)\n",
    "\n",
    "print('Train Accuracy: %.3f, Test Accuracy: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2019 Wimbledon Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019 = pd.read_csv('data/wimbledon_2019.csv')\n",
    "df_raw = pd.read_csv('data/mens/combined_raw_data.csv')\n",
    "\n",
    "df_2019['Date'] = '2019/07/07'\n",
    "df_2019['Surface'] = 'Grass'\n",
    "df_2019['diff_rank'] = df_2019['player_0_rank'] - df_2019['player_1_rank']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating features to make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Player Career Stats All Surface\n",
      "Creating Player Career Stats on Grass/Clay/Hard\n",
      "Creating Player Career Stats All Surface Last 52 Weeks\n",
      "Creating Player Career Stats on Grass/Clay/Hard Last 60 Weeks\n",
      "Creating Player Head to Head Career Stats All Surface\n",
      "Creating Player Head to Head Career Stats On Grass\n",
      "Creating Difference Variables\n"
     ]
    }
   ],
   "source": [
    "df_2019 = create_features(df_2019, df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Predictions\n",
    "    - Outcome 0 indicates player_0 will win and outcome 1 indicates player_1 will win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Round</th>\n",
       "      <th>player_0</th>\n",
       "      <th>player_1</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Round of 16</td>\n",
       "      <td>Djokovic N.</td>\n",
       "      <td>Humbert U.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.898167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Round of 16</td>\n",
       "      <td>Goffin D.</td>\n",
       "      <td>Verdasco F.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.599459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Round of 16</td>\n",
       "      <td>Raonic M.</td>\n",
       "      <td>Pella G.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.821116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Round of 16</td>\n",
       "      <td>Bautista Agut R.</td>\n",
       "      <td>Paire B.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.752442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Round of 16</td>\n",
       "      <td>Querrey S.</td>\n",
       "      <td>Sandgren T.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.748146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Round of 16</td>\n",
       "      <td>Nadal R.</td>\n",
       "      <td>Sousa J.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.914172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Round of 16</td>\n",
       "      <td>Nishikori K.</td>\n",
       "      <td>Kukushkin M.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.865524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Round of 16</td>\n",
       "      <td>Federer R.</td>\n",
       "      <td>Berrettini M.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.818423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Quarter</td>\n",
       "      <td>Djokovic N.</td>\n",
       "      <td>Goffin D.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.825125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Quarter</td>\n",
       "      <td>Bautista Agut R.</td>\n",
       "      <td>Pella G.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Quarter</td>\n",
       "      <td>Nadal R.</td>\n",
       "      <td>Querrey S.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.841475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Quarter</td>\n",
       "      <td>Federer R.</td>\n",
       "      <td>Nishikori K.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.767536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Semis</td>\n",
       "      <td>Djokovic N.</td>\n",
       "      <td>Bautista Agut R.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.740002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Semis</td>\n",
       "      <td>Djokovic N.</td>\n",
       "      <td>Pella G.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.909118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Semis</td>\n",
       "      <td>Nadal R.</td>\n",
       "      <td>Federer R.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.556334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Finals</td>\n",
       "      <td>Djokovic N.</td>\n",
       "      <td>Federer R.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.731629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Finals</td>\n",
       "      <td>Djokovic N.</td>\n",
       "      <td>Nadal R.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.721060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Round          player_0          player_1  prediction  probability\n",
       "0   Round of 16       Djokovic N.        Humbert U.           0     0.898167\n",
       "1   Round of 16         Goffin D.       Verdasco F.           0     0.599459\n",
       "2   Round of 16         Raonic M.          Pella G.           0     0.821116\n",
       "3   Round of 16  Bautista Agut R.          Paire B.           0     0.752442\n",
       "4   Round of 16        Querrey S.       Sandgren T.           0     0.748146\n",
       "5   Round of 16          Nadal R.          Sousa J.           0     0.914172\n",
       "6   Round of 16      Nishikori K.      Kukushkin M.           0     0.865524\n",
       "7   Round of 16        Federer R.     Berrettini M.           0     0.818423\n",
       "8       Quarter       Djokovic N.         Goffin D.           0     0.825125\n",
       "9       Quarter  Bautista Agut R.          Pella G.           0     0.527465\n",
       "10      Quarter          Nadal R.        Querrey S.           0     0.841475\n",
       "11      Quarter        Federer R.      Nishikori K.           0     0.767536\n",
       "12        Semis       Djokovic N.  Bautista Agut R.           0     0.740002\n",
       "13        Semis       Djokovic N.          Pella G.           0     0.909118\n",
       "14        Semis          Nadal R.        Federer R.           0     0.556334\n",
       "15       Finals       Djokovic N.        Federer R.           0     0.731629\n",
       "16       Finals       Djokovic N.          Nadal R.           0     0.721060"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_16 = df_2019[features_list]\n",
    "\n",
    "df_2019['prediction'] = saved_model.predict_classes(features_16)\n",
    "df_2019['probability'] = 1 - np.abs(df_2019.prediction - saved_model.predict_proba(features_16).flatten())\n",
    "\n",
    "df_2019[['Round', 'player_0', 'player_1', 'prediction', 'probability']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
